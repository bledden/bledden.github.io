---
import BaseHead from '../components/BaseHead.astro';
import Footer from '../components/Footer.astro';
import Header from '../components/Header.astro';
import { SITE_DESCRIPTION, SITE_TITLE } from '../consts';
---

<!doctype html>
<html lang="en">
	<head>
		<BaseHead title={SITE_TITLE} description={SITE_DESCRIPTION} />
	</head>
	<body>
		<Header />
		<main>
			<h1>Blake Ledden</h1>
			<p>
				I run experiments on LLM training dynamics and write about what I find. Currently focused on
				distillation, constitutional training, and reinforcement learning — with an emphasis on
				statistical rigor (10-seed validation, effect sizes, confidence intervals).
			</p>

			<h2>Recent Research</h2>
			<p>
				I recently completed a series of experiments on the <a href="https://thinkingmachines.ai/tinker/">Tinker platform</a>,
				testing proposals from the <a href="https://github.com/thinking-machines-lab/tinker-project-ideas">Thinking Machines Lab</a>.
				Key findings:
			</p>
			<ul>
				<li>
					<strong><a href="/blog/context-distillation">The Distribution Cliff</a></strong> —
					Hybrid distillation (off-policy → on-policy) catastrophically fails with capability gaps.
					160 runs across Qwen and Llama families. The GKD paper's recommendation doesn't generalize.
				</li>
				<li>
					<strong><a href="/blog/open-character-training">Open Character Training</a></strong> —
					Constitutional DPO improves character alignment +39%, reduces adversarial break rate from 65% to 35%.
					Prompt distillation works (84% success without system prompts). 47 runs, 5 personas.
				</li>
				<li>
					<strong><a href="/blog/memorization-study">SL vs RL Efficiency</a></strong> —
					Empirically validated "LoRA without regret" theory. Supervised learning converges in 2 episodes
					regardless of problem size. RL scales as n^0.89. Effect size: g = -8.2.
				</li>
			</ul>
			<p>
				<a href="/blog">See all posts →</a>
			</p>

			<h2>Facilitair</h2>
			<p>
				I'm also founder at <strong>Facilitair.ai</strong>, building AI orchestration systems.
				Trained 20+ model versions (44.7M-5.75B params) achieving 90%+ routing accuracy with &lt;100ms latency.
				The system predicts execution strategy, task domain, required capabilities, and optimal model simultaneously.
			</p>

			<h2>Background</h2>
			<p>
				Previously 4+ years at Apple on authentication and developer tooling. Before that,
				startups and IT roles where I kept finding problems that could be automated.
			</p>

			<h2>Links</h2>
			<ul>
				<li><a href="https://github.com/bledden">GitHub</a></li>
				<li><a href="https://linkedin.com/in/blakeledden">LinkedIn</a></li>
				<li><a href="mailto:blake.ledden@gmail.com">blake.ledden@gmail.com</a></li>
			</ul>
		</main>
		<Footer />
	</body>
</html>
